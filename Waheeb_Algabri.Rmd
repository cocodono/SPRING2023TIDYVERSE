---
title: "TidyVerse Project"
author: "waheeb Algabri"
output:
  html_document:
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(openintro)
```


# Introduction 

In this project, our goal is to create a programming example or "vignette" that showcases the capabilities of a TidyVerse package, along with a dataset from either fivethirtyeight.com or Kaggle. The aim of this example is to demonstrate how to effectively use the selected TidyVerse package to manipulate, analyze, and visualize the selected dataset. By doing so, readers will gain a better understanding of the potential of TidyVerse packages and how they can be used to solve real-world data problems.


## Data wrangling

*The dataset we used is called `Suicide Rates Overview 1985 to 2021` and it contains information about suicide rates in various countries from 1985 to 2021.*

(Suicide data)[https://www.kaggle.com/datasets/omkargowda/suicide-rates-overview-1985-to-2021]

##### Load require packages 


```{r}
library(tidyverse)
```

##### Load the dataset

```{r}
df <- read.csv("master.csv")
```



```{r}
glimpse(df)
```

```{r}
knitr::kable(head(df,5))
```


```{r results='hide'}
is.na(df)
```


Delete missing data 

```{r}
master <- na.omit(df)

```



```{r , echo=FALSE}

library(DT)

datatable(head(master),
          options = list(pageLength = 5, scrollX = TRUE, scrollY = "300px") 
        
)

```

##### Filtering for one year

By filtering data, analysts can focus on a subset of the data that is relevant to a particular research question or analysis, and exclude data that is not needed.



```{r}
# Filter the master dataset for the year 2020
master_filtered <- master %>% 
  filter(year == 2020)


datatable(head(master_filtered), 
          options = list(pageLength = 5, scrollX = TRUE, scrollY = "300px")) 
```

##### Filtering for one country and one year


if you are searching for a particular country, you can employ the following code.

```{r}

# Find all unique values in the country column
distinct_countries <- master %>% 
  distinct(country)

# View the unique countries
head (distinct_countries,5)


```

I was looking for United States of America and the year 2020

```{r}
# Filter for United States of America in 2020
USA <-master %>%
filter(year == "2020", country == "United States of America")
knitr::kable(head(USA,5))
```


##### selecting certain columns from the dataset using the select()

```{r}

master_selected <- master %>%
  select(country, year, sex, age, population)

head(master_selected, 5)

```


##### create a new variable based on existing variables using the mutate()


```{r}
# Create a new variable that calculates the percentage of the population in each age group
master_mutated <- master_selected %>%
  mutate(percent_population = population / sum(population) * 100)

# View the first 5 rows of the resulting data frame
head(master_mutated, 5)

```


group the data by certain variables using the group_by() function.

```{r}
# Group the data by country, year, and sex
master_grouped <- master_mutated %>%
  group_by(country, year, sex)

# View the grouped data frame
master_grouped

```


summarize the data to get summary statistics using the summarize() function.


```{r}
# Summarize the grouped data to get the total population for each combination of country, year, and sex
master_summarized <- master_grouped %>%
  summarize(total_population = sum(population))

# View the resulting data frame
head(master_summarized)

```

# Analysis 


##### The top 10 Countries with the Highest Number of Suicides in 2020


```{r}
library(ggplot2)
library(tidyr)

# Filter for 2020 data
suicides_2020 <- master %>% 
  filter(year == 2020)

# Group by country and calculate total number of suicides
suicides_by_country <- suicides_2020 %>% 
  group_by(country) %>% 
  summarize(total_suicides = sum(suicides_no)) %>%
  replace_na(list(total_suicides = 0))

# Select top 10 countries by total number of suicides
top_10_countries <- suicides_by_country %>%
  top_n(10, total_suicides) %>%
  arrange(desc(total_suicides))

# Create bar plot of top 10 countries
ggplot(top_10_countries, aes(x = country, y = total_suicides, fill = country)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Top 10 Countries with the Highest Number of Suicides in 2020")

```


###### The 10 countries with the lowest number of suicides in 2020


```{r}
# Select bottom 10 countries by total number of suicides
bottom_10_countries <- suicides_by_country %>%
  top_n(-10, total_suicides) %>%
  arrange(total_suicides)

# Create bar plot of bottom 10 countries
ggplot(bottom_10_countries, aes(x = country, y = total_suicides, fill = country)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Bottom 10 Countries with the Lowest Number of Suicides in 2020")

```




```{r}
library(tidyverse)
library(ggplot2)

# Read in the data
master <- read.csv("master.csv")

# Filter for 2020 data only
master_filtered <- master %>% 
  filter(year == 2020)

# Create a subset of the data for the top 10 countries with the highest suicide rates in 2020
top10 <- master_filtered %>% 
  group_by(country) %>% 
  summarize(suicides_per_100k = sum(suicides.100k.pop, na.rm = TRUE)) %>% 
  arrange(desc(suicides_per_100k)) %>% 
  top_n(10)

# Create a subset of the data for Guatemala
guatemala <- master_filtered %>% 
  filter(country == "Guatemala")

# Calculate the total number of suicides in Guatemala in 2020
guatemala_total_suicides <- sum(guatemala$suicides_no, na.rm = TRUE)

# Calculate the total population of Guatemala in 2020
guatemala_total_population <- sum(guatemala$population, na.rm = TRUE)

# Calculate the suicide rate per 100,000 people in Guatemala in 2020
guatemala_suicide_rate <- guatemala_total_suicides / guatemala_total_population * 100000

# Create a data frame with the suicide rate for Guatemala and the top 10 countries with the highest suicide rates
comparison_data <- rbind(
  data.frame(country = "Guatemala", suicides_per_100k = guatemala_suicide_rate),
  top10
)

# Add a column indicating whether each country is in the top 10 or not
comparison_data$highlight <- ifelse(comparison_data$country == "United States" | comparison_data$country %in% top10$country, "Yes", "No")

# Create a bar chart showing the suicide rate for Guatemala and the top 10 countries, with highlighting for the top 10 countries
ggplot(comparison_data, aes(x = country, y = suicides_per_100k, fill = highlight)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Comparison of Suicide Rates in Guatemala and Top 10 Countries with Highest Suicide Rates in 2020",
       x = "Country", y = "Suicides per 100,000 people",
       fill = "Highlight") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "bottom",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```


# conclusion 

we have explored the TidyVerse package and its capabilities for manipulating, analyzing, and visualizing datasets using R programming language.

By following the steps outlined in this project, some commonly used TidyVerse packages include dplyr for data manipulation, tidyr for data cleaning, ggplot2 for data visualization, readr for reading data

---

# Extension by Keith Colella

As an extension to the above vignette, we'll walk through an analysis of crime rates in Philadelphia, highlighting various features of the tidyverse along the way. We'll primarily make use of `dplyr`, `ggplot` and `forcats` functions.

Our data will be pulled from the City of Philadelphia's OpenPhillyData site: https://opendataphilly.org/datasets/crime-incidents/. The site provides an API, which can be queried using SQL (specifically PostgreSQL). OpenPhillyData even offers an R package — `rphl` — to facilitate queries, which can be installed using the `remotes` package (remotes::install_github("CityOfPhiladelphia/rphl").

```{r}
library(rphl)
```

We'll begin by defining our query and submitting it via the `rphl` package's `get_carto` function. In this query, we request counts of various types of crimes per year.

```{r}
query_crime <- paste("SELECT Text_General_Code, COUNT(*) AS n,",
                        "DATE_PART('YEAR', Dispatch_Date_Time) AS Year",
                     "FROM incidents_part1_part2",
                     "GROUP BY Year, Text_General_Code",
                     "ORDER BY Year, n")

crime <- get_carto(query_crime, format = "csv") %>%
  filter(year != 2023)

crime %>%
  head(10) %>%
  knitr::kable()

crime %>%
  ggplot(aes(year, n, color = text_general_code)) +
  geom_line() +
  theme(legend.position = 'bottom')
```

In previewing our dataframe and generating a line plot, we see that we have too many levels in the `Text_General_Code` field to handle simultaneously. However, we can use tidyverse features to map in additional data and simplify this factor in support of more streamlined analysis.

We begin with another query that creates a mapping between `Text_General_Code` and the `UCR_General` codes, which are more consolidated. 

```{r}
query_mapping <- paste("SELECT UCR_General, Text_General_Code",
                       "FROM incidents_part1_part2",
                       "GROUP BY UCR_General, Text_General_Code",
                       "ORDER BY UCR_General")

mapping <- get_carto(query_mapping, format = "csv")

mapping %>%
  arrange(ucr_general) %>%
  head(10) %>%
  knitr::kable()
```

The `UCR_General` field still has a few too many levels, so we'll use the `mutate` function to generate a new field, `code_simple`. Within `mutate`, we'll leverage the `case_when` function to manually determine how each of the 26 code categories should be reclassified.

```{r}
mapping <- mapping %>%
  mutate(code_simple = case_when(ucr_general == 100 ~ 'Homocide',
                                 ucr_general == 200 ~ 'Rape',
                                 ucr_general == 300 ~ 'Robbery/Burglary',
                                 ucr_general == 400 ~ 'Assault',
                                 ucr_general == 500 ~ 'Robbery/Burglary',
                                 ucr_general == 600 ~ 'Theft',
                                 ucr_general == 700 ~ 'Theft',
                                 ucr_general == 800 ~ 'Assault',
                                 ucr_general == 900 ~ 'Arson',
                                 ucr_general == 1000 ~ 'Forgery/Fraud',
                                 ucr_general == 1100 ~ 'Forgery/Fraud',
                                 ucr_general == 1200 ~ 'Forgery/Fraud',
                                 ucr_general == 1300 ~ 'Forgery/Fraud',
                                 ucr_general == 1400 ~ 'Vandalism',
                                 ucr_general == 1500 ~ 'Weapons',
                                 ucr_general == 1600 ~ 'Prostitution/Vice',
                                 ucr_general == 1700 ~ 'Prostitution/Vice',
                                 ucr_general == 1800 ~ 'Narcotics',
                                 ucr_general == 1900 ~ 'Prostitution/Vice',
                                 ucr_general == 2000 ~ 'Other',
                                 ucr_general == 2100 ~ 'DUI',
                                 ucr_general == 2200 ~ 'Other',
                                 ucr_general == 2300 ~ 'Other',
                                 ucr_general == 2400 ~ 'Other',
                                 ucr_general == 2500 ~ 'Other',
                                 ucr_general == 2600 ~ 'Other'))

mapping %>% select(text_general_code) %>% unique() %>% nrow()
mapping %>% select(code_simple) %>% unique() %>% nrow()
```

We can see that we've reduced the number of levels in our crime coding from 33 to 13. We're now able to use the `left_join` from `dplyr` to bring this simplified code field into our crime dataframe. Following the join, we can use `group_by` and `summarize` to consolidate the crime tallies under the new, simplified classifications.

```{r}
crime_simple <- crime %>%
  left_join(
    select(mapping, text_general_code, code_simple)) %>%
  group_by(year, code_simple) %>%
  summarize(count = sum(n), .groups = 'keep')

crime_simple %>%
  head(10) %>%
  knitr::kable()

crime_simple %>%
  ggplot(aes(year, count, color = code_simple)) +
  geom_line() +
  theme(legend.position = 'bottom') +
  scale_y_continuous(labels = scales::comma)
```

Our plot is now much more interpretable. However, there still appears to be a few too many levels to see the finer details, so it will be best to simplify this field a bit further. We'll again use `mutate` to redefine the field, but instead of `case_when` we can use a different function from the `forcats` package: `fct_collapse`. After coercing the character field into a factor, we can then create new levels, listing out each of the constituent levels from the previous classification. We'll single out Homicide, then create another level for other violent crimes, then collapse all other crimes into the Non-Violent category.

```{r}
crime_simpler <- crime_simple %>%
  mutate(code_simple = as.factor(code_simple),
         code_simple = factor(fct_collapse(
           code_simple,
           Homocide = c('Homocide'),
           Rape_Assault_Burglary = c('Rape','Robbery/Burglary','Arson','Assault'),
           other_level = 'Non-Violent')),
         ordered = TRUE) %>%
  group_by(year, code_simple) %>%
  summarize(count = sum(count), .groups = 'keep') %>%
  ungroup()

crime_simpler %>%
  head(10) %>%
  knitr::kable()

crime_simpler %>%
  ggplot(aes(year, count)) +
  geom_line() +
  facet_grid(rows = vars(code_simple),
             scales = 'free') +
  scale_y_continuous(labels = scales::comma)
```

We now have a clean plot to facilitate analysis. The plot shows that both Non-Violent and Violent Crimes excluding homocide have steadily decreased since 2006, with slight upticks in 2022. The level of homicides, however, shows a different path. After some slight declines through ~2014, the number of homicides has steadily increased. The increase between 2019 and 2020 appears especially pronounced.

This raises a question. The plot above shows *absolute* counts of crimes, so it is unclear whether crime *rates* have increased. In other words, is the increase in homicide rates simply a reflection of an increasing population?

To answer this question, we'll pull in one final dataset from OpenDataPhilly, this one detailing the total population of Philadelphia County. This dataset is available directly in .csv format, so we can use the `read_csv` function from `readr`. We'll also use the `filter` function from `dplyr` to remove unwanted rows, focusing only on total population counts each year.

```{r}
pop <- read_csv(paste0('https://opendata.arcgis.com/api/v3/datasets/',
                       'd0ac67bb117b42f39614bad23525a13e_0/downloads/',
                       'data?format=csv&spatialRefId=4326'))

pop_annual <- pop %>%
  filter(SEX == 'All sexes',
         RACE_ETHNICITY == 'All races/ethnicities',
         AGE_CATEGORY == 'All ages',
         SOURCE == 'Annual County Resident Population Estimates')

pop_annual %>%
  tail(10) %>%
  knitr::kable()
```

As above, we'll use the `left_join` function to map in the population counts per year, and the `mutate` function to calculate crime rates, defined as number of crimes divided by total population. We'll then generate a final plot to compare crimes total and rates per category over time.

```{r}
crime_simpler_pop <- crime_simpler %>%
  left_join(select(pop_annual, YEAR, COUNT_),
            by = c('year' = 'YEAR')) %>%
  rename(population = COUNT_) %>%
  fill(population, .direction = 'down') %>%
  mutate(rate = count / population)

crime_simpler_pop %>%
  pivot_longer(cols = c(count, rate),
               names_to = 'measure') %>%
  ggplot() +
  geom_line(aes(year, value)) +
  facet_wrap(measure ~ code_simple,
             # rows = vars(code_simple),
             # cols = vars(measure),
             scales = 'free') +
  scale_y_continuous(labels = scales::comma)
```

Surprisingly, the plots of crime counts and rates match almost exactly, indicating the crime overall has kept pace with increases in total population. On the one hand, this indicates that most crime is steadily decreasing. At the same time, homicide rates have continued to climb despite the decreases in other categories.

--- 

In conclusion, we see that the tidyverse offers a variety of tools to gather, clean and compile data efficiently and intuitively. 